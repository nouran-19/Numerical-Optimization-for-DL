# Numerical-Optimization-for-DL
Optimization algorithms for Deep Learning networks, from scratch

## Notebooks Cover
* Notebook 1: Single and Multivariate LR
* Notebook 2: Batch, Stochastic, and Mini Batch Gradient Descent (GC)
* Notebook 3: Accelerated GD, Momentum and Nestrov Accelerated Gradient (NAG)
* Notebook 4: Adaptive Gradient (AdaGrad), Root Mean Square Propagation (RMSProp), Adaptive Moment Estimation (ADAM)
* Notebook 5: Newton's Method -> (single and multi variable), Quasi-Newton -> BFGS